Can this sub prompt be written better for this model, optimise for lower token cost and lower context usage without sacraficing quality, avoid numbering: